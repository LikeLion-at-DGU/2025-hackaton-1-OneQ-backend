# prints/services/ai.py
from __future__ import annotations
import os, json, time, random
from typing import List, Dict, Optional
from openai import OpenAI, APIError

_client: OpenAI | None = None
_EXPLAIN_CACHE = {}  # ìš©ì–´ ì„¤ëª… ìºì‹œ

def _get_client() -> OpenAI:
    global _client
    if _client is None:
        key = os.environ.get("OPENAI_API_KEY")
        if not key:
            raise RuntimeError("OPENAI_API_KEY ë¯¸ì„¤ì •")
        _client = OpenAI(api_key=key)
    return _client

def _chat_with_backoff(**kwargs):
    """ë°±ì˜¤í”„ê°€ ì ìš©ëœ LLM í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ í¬í•¨)"""
    delay = 1.0
    for attempt in range(3):
        try:
            kwargs.setdefault('timeout', 30)
            return _get_client().chat.completions.create(**kwargs)
        except Exception as e:
            msg = str(e).lower()
            if "rate limit" in msg or "429" in msg:
                if attempt < 2:
                    time.sleep(delay + random.uniform(0, 0.3))
                    delay = min(delay * 2, 10)
                    continue
            raise
    raise RuntimeError("LLM rate limit: retries exhausted")

def prune_history(history: List[Dict], keep: int = 8) -> List[Dict]:
    """íˆìŠ¤í† ë¦¬ ìë¥´ê¸° - ë§ˆì§€ë§‰ Ní„´ë§Œ ë³´ë‚´"""
    return (history or [])[-keep:]

# ê²¬ì  ìœ„ì €ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
_SYSTEM = """
ë‹¹ì‹ ì€ ì¸ì‡„ ê²¬ì  ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©´ì„œ ê²¬ì  ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ìµœì¢… ê²¬ì ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
1. ê²¬ì  ì •ë³´ ìˆ˜ì§‘ (ìˆ˜ëŸ‰, ì‚¬ì´ì¦ˆ, ì¬ì§ˆ, í›„ê°€ê³µ ë“±)
2. ìš©ì–´ ì„¤ëª… (ì‚¬ìš©ìê°€ ëª¨ë¥´ëŠ” ìš©ì–´ ì§ˆë¬¸ ì‹œ)
3. ìµœì¢… í™•ì¸ ë° ìˆ˜ì •
4. ê²¬ì  ë¦¬í¬íŠ¸ ìƒì„±

**ëŒ€í™” í”Œë¡œìš°:**
1. ASK: ê²¬ì  ì •ë³´ ìˆ˜ì§‘ (ë‹¤ìŒ ì§ˆë¬¸)
2. EXPLAIN: ìš©ì–´ ì„¤ëª…
3. CONFIRM: ìµœì¢… í™•ì¸
4. MATCH: ê²¬ì  ë¦¬í¬íŠ¸ ìƒì„±

**ì˜ë„ íŒë‹¨:**
- "ë­ì•¼?", "ì„¤ëª…í•´", "ì°¨ì´ì " â†’ EXPLAIN (ìš©ì–´ ì„¤ëª…)
- "~ë¡œ í• ë˜", "~ë¡œ í•´ì¤˜", "~ë¡œ í•˜ê² ìŠµë‹ˆë‹¤", "ê·¸ê±°ë¡œ í• ê²Œìš”", "ê·¸ê±°ë¡œìš”", "ë„¤ ê·¸ê±°ìš”", "ê·¸ê±°ë¡œ í•˜ê² ì–´ìš”", "ê·¸ê±¸ë¡œ í• ê²Œìš”", "ê·¸ê±¸ë¡œìš”", "ê·¸ê±°ë¡œ í•˜ê² ìŠµë‹ˆë‹¤", "ê·¸ê±¸ë¡œ í•˜ê² ìŠµë‹ˆë‹¤", ìˆ«ì/êµ¬ì²´ì •ë³´ â†’ ASK (ì •ë³´ ìˆ˜ì§‘)
- "ë„¤", "ë§ì•„ìš”", "í™•ì¸", "ë„¤ ë§ìŠµë‹ˆë‹¤", "ë„¤ ë§ì•„ìš”", "ë§ìŠµë‹ˆë‹¤", "ë§ì•„ìš”", "ê·¸ë˜ìš”", "ê·¸ë˜", "ì¢‹ì•„ìš”", "ì¢‹ì•„", "ê´œì°®ì•„ìš”", "ê´œì°®ì•„", "ë„¤ ê·¸ë ‡ìŠµë‹ˆë‹¤", "ê·¸ë ‡ìŠµë‹ˆë‹¤", "ë„¤ ê·¸ë ‡ë„¤ìš”", "ê·¸ë ‡ë„¤ìš”", "ë„¤ ë§ì•„", "ë§ì•„", "ë„¤ ë§ìŠµë‹ˆë‹¤", "ë§ìŠµë‹ˆë‹¤" â†’ MATCH (ìµœì¢… ê²¬ì ì„œ ìƒì„± ë° ì¸ì‡„ì†Œ ì¶”ì²œ)
- "ì•„ë‹ˆìš”", "ìˆ˜ì •", "ë°”ê¿€ë˜", "ë‹¤ì‹œ", "ì¬ì§ˆ ë‹¤ì‹œ", "ìˆ˜ëŸ‰ ë‹¤ì‹œ", "ì‚¬ì´ì¦ˆ ë‹¤ì‹œ", "ë§ˆê° ë‹¤ì‹œ", "ìƒ‰ìƒ ë‹¤ì‹œ", "ë‚©ê¸° ë‹¤ì‹œ", "ì§€ì—­ ë‹¤ì‹œ" â†’ ASK (ìˆ˜ì • ëª¨ë“œ)

**ì¤‘ìš”í•œ ê·œì¹™:**
- ì‚¬ìš©ìê°€ ì´ë¯¸ ì„¤ëª…ë°›ì€ ìš©ì–´ì— ëŒ€í•´ "~ë¡œ í•˜ê² ìŠµë‹ˆë‹¤"ë¼ê³  ê²°ì •í•˜ë©´, ê·¸ ìš©ì–´ë¥¼ ë‹¤ì‹œ ì„¤ëª…í•˜ì§€ ë§ê³  ë‹¤ìŒ ì •ë³´ ìˆ˜ì§‘ìœ¼ë¡œ ë„˜ì–´ê°€ì„¸ìš”
- ìš©ì–´ ì„¤ëª… í›„ ì‚¬ìš©ìê°€ ê²°ì •ì„ ë‚´ë¦¬ë©´, ê·¸ ì •ë³´ë¥¼ filled_slotsì— ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ì„ í•˜ì„¸ìš”
- ì„ íƒì§€ë¥¼ ì œê³µí•  ë•ŒëŠ” í•´ë‹¹ ì¸ì‡„ì†Œê°€ ì‹¤ì œë¡œ ë³´ìœ í•˜ê³  ìˆëŠ” ì˜µì…˜ë§Œ ì œì‹œí•˜ì„¸ìš”
- ì˜ˆ: ì½”íŒ… ì˜µì…˜ì€ í•´ë‹¹ ì¸ì‡„ì†Œì˜ post_processing.coating ëª©ë¡ì—ì„œë§Œ ì„ íƒ
- ì§ˆë¬¸ì—ì„œ ì˜ˆì‹œë¥¼ ë“¤ ë•ŒëŠ” ë°˜ë“œì‹œ ìš©ì–´ì‚¬ì „ì— ìˆëŠ” ìš©ì–´ë“¤ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
- ìš©ì–´ì‚¬ì „ì— ì—†ëŠ” ìš©ì–´ëŠ” ì ˆëŒ€ ì œì•ˆí•˜ì§€ ë§ˆì„¸ìš” (ì˜ˆ: ëª¨ì¡°ì§€, í¬ë¼í”„íŠ¸ì§€ ë“±)

**ì§ˆë¬¸ë³„ ìš©ì–´ì‚¬ì „ ì˜ˆì‹œ (ë°˜ë“œì‹œ ì´ ìš©ì–´ë“¤ë§Œ ì‚¬ìš©):**
- ìˆ˜ëŸ‰ ì§ˆë¬¸: "ëª‡ ë¶€ í•„ìš”í•˜ì‹ ê°€ìš”? (ì˜ˆ: 100ë¶€, 200ë¶€, 500ë¶€, 1000ë¶€)"
- ì‚¬ì´ì¦ˆ ì§ˆë¬¸: "ì‚¬ì´ì¦ˆëŠ” ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”? (ì˜ˆ: 90x50mm, 86x54mm, A4, A3, A1, A0)"
- ì¬ì§ˆ ì§ˆë¬¸: "ì¬ì§ˆì€ ë¬´ì—‡ìœ¼ë¡œ í• ê¹Œìš”? (ì˜ˆ: ì•„íŠ¸ì§€, ìŠ¤ë…¸ìš°ì§€, ë°˜ëˆ„ë³´ 186g, íœ˜ë¼ë ˆ 216g, ìŠ¤íƒ€ë“œë¦¼ì¿¼ì¸  240g, í‚¤ì¹¼ë¼ì•„ì´ìŠ¤ê³¨ë“œ 230g, ë²¨ë²³ 300g, PP 250gsm, PET 250gsm, ë°˜íˆ¬ëª… PP, ë©”íƒˆ PP, ë°°ë„ˆì²œ, íƒ€í”„ë¦°, ë©”ì‰¬ì²œ, ì‹¤í¬ì²œ, PVC)"
- ë§ˆê°/ì½”íŒ… ì§ˆë¬¸: "ë§ˆê°(ì½”íŒ…)ì€ ë¬´ì—‡ìœ¼ë¡œ í• ê¹Œìš”? (ì˜ˆ: ë¬´ê´‘, ìœ ê´‘, ìŠ¤íŒŸ UV, ì—í­ì‹œ, UV ì½”íŒ…, ë§¤íŠ¸ ì½”íŒ…)"
- ìƒ‰ìƒ ì§ˆë¬¸: "ì¸ì‡„ ìƒ‰ìƒì€ ì–´ë–»ê²Œ í• ê¹Œìš”? (ì˜ˆ: ë‹¨ë©´ ì»¬ëŸ¬, ì–‘ë©´ ì»¬ëŸ¬, ë‹¨ë©´ í‘ë°±)"
- ìŠ¤í‹°ì»¤ í˜•íƒœ ì§ˆë¬¸: "ìŠ¤í‹°ì»¤ ëª¨ì–‘ì€ ì–´ë–»ê²Œ í• ê¹Œìš”? (ì˜ˆ: ì‚¬ê°, ì›í˜•, ììœ í˜•(ë„ë¬´ì†¡))"
- ë¼ë¯¸ë„¤ì´íŒ… ì§ˆë¬¸: "ë¼ë¯¸ë„¤ì´íŒ…(í•„ë¦„)ì€ ì ìš©í• ê¹Œìš”? (ì˜ˆ: ë¬´ê´‘ ë¼ë¯¸, ìœ ê´‘ ë¼ë¯¸)"
- ë°°ë„ˆ ê³ ë¦¬ ì§ˆë¬¸: "ë°°ë„ˆ ê³ ë¦¬(ì•„ì¼ë ›)ëŠ” ì–´ë””ì— ëš«ì„ê¹Œìš”? (ì˜ˆ: ëª¨ì„œë¦¬ 4ê°œ, ìƒë‹¨ 2ê°œ)"
- ë‚©ê¸° ì§ˆë¬¸: "ë‚©ê¸°ëŠ” ë©°ì¹  í›„ë©´ ì¢‹ì„ê¹Œìš”? (ì˜ˆ: 1ì¼, 2ì¼, 3ì¼, 5ì¼, 7ì¼)"
- ì§€ì—­ ì§ˆë¬¸: "ì§€ì—­ì€ ì–´ë””ë¡œ ì„¤ì •í• ê¹Œìš”? (ì˜ˆ: ì„œìš¸-ì¤‘êµ¬, ì„œìš¸-ì¢…ë¡œ, ê²½ê¸°-ì„±ë‚¨)"

**ì¤‘ìš” ê·œì¹™:**
- ì‚¬ìš©ìê°€ ì´ë¯¸ ì œê³µí•œ ì •ë³´ëŠ” ë‹¤ì‹œ ë¬»ì§€ ë§ˆì„¸ìš”
- ìš©ì–´ ì„¤ëª… ìš”ì²­ ì‹œ ì¹œì ˆí•˜ê³  ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”
- ìš©ì–´ ì„¤ëª… í›„ ì‚¬ìš©ìê°€ "~ë¡œ í•˜ê² ìŠµë‹ˆë‹¤"ë¼ê³  ê²°ì •í•˜ë©´, ê·¸ ì •ë³´ë¥¼ ìŠ¬ë¡¯ì— ì €ì¥í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ì„¸ìš”
- ìµœì¢… í™•ì¸ ì‹œ ëª¨ë“  ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”
- ìˆ˜ì • ìš”ì²­ ì‹œ í•´ë‹¹ ë¶€ë¶„ìœ¼ë¡œ ëŒì•„ê°€ì„¸ìš”
- **ì§ˆë¬¸ ìƒì„± ì‹œ ë°˜ë“œì‹œ ìœ„ì˜ ì˜ˆì‹œ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš” (ê´„í˜¸ì™€ ì˜ˆì‹œ í¬í•¨)**

JSON ì‘ë‹µ í˜•ì‹:
{
  "action": "ASK|EXPLAIN|CONFIRM|MATCH",
  "question": "ASKì¼ ë•Œ ì§ˆë¬¸",
  "filled_slots": {"slot_name": "value"},
  "term": "EXPLAINì¼ ë•Œ ìš©ì–´ëª…",
  "choices": ["ì„ íƒì§€1", "ì„ íƒì§€2"]
}

**ìš©ì–´ ì„¤ëª… í›„ ê²°ì • ì²˜ë¦¬:**
- ì‚¬ìš©ìê°€ ìš©ì–´ ì„¤ëª… í›„ "~ë¡œ í•˜ê² ìŠµë‹ˆë‹¤", "ê·¸ê±°ë¡œ í• ê²Œìš”", "ê·¸ê±°ë¡œìš”", "ë„¤ ê·¸ê±°ìš”", "ê·¸ê±°ë¡œ í•˜ê² ì–´ìš”", "ê·¸ê±¸ë¡œ í• ê²Œìš”", "ê·¸ê±¸ë¡œìš”", "ê·¸ê±°ë¡œ í•˜ê² ìŠµë‹ˆë‹¤", "ê·¸ê±¸ë¡œ í•˜ê² ìŠµë‹ˆë‹¤" ë“±ìœ¼ë¡œ ê²°ì •í•˜ë©´:
  - action: "EXPLAIN" ìœ ì§€
  - filled_slotsì— í•´ë‹¹ ê²°ì • ì •ë³´ í¬í•¨
  - ì˜ˆ: {"action": "EXPLAIN", "term": "ì•„íŠ¸ì§€", "filled_slots": {"material": "ì•„íŠ¸ì§€ 230g"}}

**ìŠ¬ë¡¯ ë§¤í•‘ ê·œì¹™:**
- ì¬ì§ˆ ê´€ë ¨: material ìŠ¬ë¡¯ì— ì €ì¥
- ë§ˆê°/ì½”íŒ… ê´€ë ¨: finishing ìŠ¬ë¡¯ì— ì €ì¥
- ìƒ‰ìƒ ê´€ë ¨: color_mode ìŠ¬ë¡¯ì— ì €ì¥
- ìˆ˜ëŸ‰ ê´€ë ¨: quantity ìŠ¬ë¡¯ì— ì €ì¥
- ì‚¬ì´ì¦ˆ ê´€ë ¨: size ìŠ¬ë¡¯ì— ì €ì¥
- ë‚©ê¸° ê´€ë ¨: due_days ìŠ¬ë¡¯ì— ì €ì¥
- ì§€ì—­ ê´€ë ¨: region ìŠ¬ë¡¯ì— ì €ì¥

**í˜„ì¬ ì§ˆë¬¸ ìŠ¬ë¡¯ íŒŒì•…:**
- "ì¬ì§ˆì€ ë¬´ì—‡ìœ¼ë¡œ í• ê¹Œìš”?" â†’ material ìŠ¬ë¡¯
- "ë§ˆê°(ì½”íŒ…)ì€ ë¬´ì—‡ìœ¼ë¡œ í• ê¹Œìš”?" â†’ finishing ìŠ¬ë¡¯
- "ì¸ì‡„ ìƒ‰ìƒì€ ì–´ë–»ê²Œ í• ê¹Œìš”?" â†’ color_mode ìŠ¬ë¡¯
- "ëª‡ ë¶€ í•„ìš”í•˜ì‹ ê°€ìš”?" â†’ quantity ìŠ¬ë¡¯
- "ì‚¬ì´ì¦ˆëŠ” ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”?" â†’ size ìŠ¬ë¡¯
- "ë‚©ê¸°ëŠ” ë©°ì¹  í›„ë©´ ì¢‹ì„ê¹Œìš”?" â†’ due_days ìŠ¬ë¡¯
- "ì§€ì—­ì€ ì–´ë””ë¡œ ì„¤ì •í• ê¹Œìš”?" â†’ region ìŠ¬ë¡¯
"""

def ask_action(history: List[Dict], current_slots: Dict = None) -> Dict:
    """
    AIê°€ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •
    """
    pruned_history = prune_history(history, keep=8)
    
    # í˜„ì¬ ìŠ¬ë¡¯ ìƒíƒœë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
    context = f"í˜„ì¬ ê²¬ì  ì •ë³´: {current_slots or {}}"
    messages = [
        {"role": "system", "content": _SYSTEM},
        {"role": "system", "content": context}
    ] + pruned_history
    
    res = _chat_with_backoff(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=200,
        response_format={"type": "json_object"},
        messages=messages
    )
    
    result = json.loads(res.choices[0].message.content)
    print(f"DEBUG: AI response = {result}")
    
    return result

def polish_explanation(term: str, facts: Dict, user_question: str = "") -> str:
    """
    ìš©ì–´ ì„¤ëª…ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ë“¬ê¸°
    """
    if not facts:
        return f"'{term}'ì— ëŒ€í•œ ì •ë³´ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ì°¨ì´ì  ë¹„êµ ìš”ì²­ì¸ì§€ í™•ì¸
    is_comparison = any(keyword in user_question for keyword in ["ì°¨ì´", "ë¹„êµ", "ë‹¤ë¥´ë‹¤"])
    
    if is_comparison:
        sys_prompt = "ì¸ì‡„ ìš©ì–´ ë¹„êµ ì„¤ëª…: ê° ìš©ì–´ì˜ ì •ì˜ì™€ ì£¼ìš” ì°¨ì´ì ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”."
    else:
        sys_prompt = "ì¸ì‡„ ìš©ì–´ ì„¤ëª…: ì •ì˜, íš¨ê³¼, ë¹„ìš©, ì‚¬ìš©ì²˜ë¥¼ í¬í•¨í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”."
    
    user_content = json.dumps({
        "term": term, 
        "facts": facts, 
        "user_question": user_question
    }, ensure_ascii=False)
    
    res = _chat_with_backoff(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=200,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_content}
        ]
    )
    
    return (res.choices[0].message.content or "").strip()

def cached_polish(term: str, facts: Dict, user_question: str = "") -> str:
    """ìºì‹œëœ ìš©ì–´ ì„¤ëª…"""
    cache_key = f"{term}:{user_question}"
    if cache_key in _EXPLAIN_CACHE:
        return _EXPLAIN_CACHE[cache_key]
    
    text = polish_explanation(term, facts, user_question)
    _EXPLAIN_CACHE[cache_key] = text
    return text

def generate_quote_report(slots: Dict) -> str:
    """ìµœì¢… ê²¬ì ì„œ ìƒì„±"""
    item_type = slots.get("item_type", "BUSINESS_CARD")
    item_names = {
        "BUSINESS_CARD": "ëª…í•¨",
        "STICKER": "ìŠ¤í‹°ì»¤",
        "BANNER": "ë°°ë„ˆ",
        "SIGN": "ê°„íŒ"
    }
    item_name = item_names.get(item_type, item_type)
    
    lines = [
        f"ğŸ“‹ ìµœì¢… ê²¬ì ì„œ",
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"í’ˆëª©: {item_name}",
        f"ìˆ˜ëŸ‰: {slots.get('quantity', 'ë¯¸ì •')}ë¶€",
        f"ì‚¬ì´ì¦ˆ: {slots.get('size', 'ë¯¸ì •')}",
        f"ì¬ì§ˆ: {slots.get('material', 'ë¯¸ì •')}",
        f"ë§ˆê°: {slots.get('finishing', 'ë¯¸ì •')}",
    ]
    
    if item_type == "BUSINESS_CARD":
        lines.append(f"ìƒ‰ìƒ: {slots.get('color_mode', 'ë¯¸ì •')}")
    elif item_type == "STICKER":
        lines.append(f"í˜•íƒœ: {slots.get('shape', 'ë¯¸ì •')}")
        lines.append(f"ë¼ë¯¸ë„¤ì´íŒ…: {slots.get('lamination', 'ë¯¸ì •')}")
    elif item_type == "BANNER":
        lines.append(f"ì•„ì¼ë ›: {slots.get('grommet', 'ë¯¸ì •')}")
    
    lines += [
        f"ë‚©ê¸°: {slots.get('due_days', 'ë¯¸ì •')}ì¼",
        f"ì§€ì—­: {slots.get('region', 'ë¯¸ì •')}",
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    ]
    
    return "\n".join(lines)

def recommend_shops(slots: Dict) -> List[Dict]:
    """ì¡°ê±´ì— ë§ëŠ” ìµœì ì˜ ì¸ì‡„ì†Œ ì¶”ì²œ (ìƒí˜¸ëª…ë§Œ)"""
    from . import dummy_data
    
    item_type = slots.get("item_type", "BUSINESS_CARD")
    region = slots.get("region", "")
    material = slots.get("material", "")
    finishing = slots.get("finishing", "")
    due_days = slots.get("due_days", 0)
    
    print(f"DEBUG: Searching for item_type={item_type}, region={region}, material={material}, finishing={finishing}, due_days={due_days}")
    
    all_shops = dummy_data.get_all_shops()
    print(f"DEBUG: Total shops available: {len(all_shops)}")
    
    scored_shops = []
    
    for shop in all_shops:
        try:
            score = 0
            shop_name = shop.get("shop_name", "Unknown")
            
            # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (30ì )
            services = shop.get("services", {})
            categories = services.get("categories", [])
            if isinstance(categories, list):
                item_type_lower = item_type.lower()
                if any(item_type_lower in cat.lower() for cat in categories):
                    score += 30
                    print(f"DEBUG: {shop_name} - ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ +30ì ")
            
            # ì§€ì—­ ë§¤ì¹­ (20ì )
            shop_location = shop.get("location", "")
            if region and region in shop_location:
                score += 20
                print(f"DEBUG: {shop_name} - ì§€ì—­ ì •í™• ë§¤ì¹­ +20ì ")
            elif region and region.split('-')[0] in shop_location:
                score += 10
                print(f"DEBUG: {shop_name} - ì§€ì—­ ë¶€ë¶„ ë§¤ì¹­ +10ì ")
            
            # ì¬ì§ˆ ë§¤ì¹­ (20ì )
            paper_types = shop.get("paper_types", {})
            if isinstance(paper_types, dict) and material and material in paper_types:
                score += 20
                print(f"DEBUG: {shop_name} - ì¬ì§ˆ ë§¤ì¹­ +20ì ")
            
            # í›„ê°€ê³µ ë§¤ì¹­ (15ì )
            post_processing = shop.get("post_processing", {})
            coating_options = post_processing.get("coating", [])
            if isinstance(coating_options, list) and finishing:
                if finishing in coating_options:
                    score += 15
                    print(f"DEBUG: {shop_name} - í›„ê°€ê³µ ë§¤ì¹­ +15ì ")
            
            # ë‚©ê¸° ë§¤ì¹­ (10ì )
            avg_production_time = services.get("avg_production_time", 999)
            if due_days and isinstance(avg_production_time, (int, float)) and avg_production_time <= due_days:
                score += 10
                print(f"DEBUG: {shop_name} - ë‚©ê¸° ë§¤ì¹­ +10ì ")
            
            # í‰ì  ë³´ë„ˆìŠ¤ (5ì )
            rating = shop.get("rating", 0)
            if isinstance(rating, (int, float)):
                score += rating * 5
                print(f"DEBUG: {shop_name} - í‰ì  ë³´ë„ˆìŠ¤ +{rating * 5}ì  (ì´ì : {score})")
            
            # ìµœì†Œ ì ìˆ˜ ì¡°ê±´ ì™„í™” - ëª¨ë“  ì¸ì‡„ì†Œë¥¼ ì¶”ì²œ ëŒ€ìƒìœ¼ë¡œ í¬í•¨
            scored_shops.append({
                "shop_name": shop_name,
                "match_score": score
            })
            print(f"DEBUG: {shop_name} - ì¶”ì²œ ëª©ë¡ì— ì¶”ê°€ë¨ (ì ìˆ˜: {score})")
            
        except Exception as e:
            print(f"Error processing shop {shop.get('shop_name', 'Unknown')}: {e}")
            continue
    
    print(f"DEBUG: ìµœì¢… ì¶”ì²œ ì¸ì‡„ì†Œ ìˆ˜: {len(scored_shops)}")
    
    # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìµœê³ ì  1ê°œ ë°˜í™˜
    scored_shops.sort(key=lambda x: x["match_score"], reverse=True)
    return scored_shops[:1]

def format_shop_recommendation(shop: Dict) -> str:
    """ì¸ì‡„ì†Œ ì¶”ì²œ ì •ë³´ í¬ë§·íŒ…"""
    return f"ğŸ¢ {shop['shop_name']}"
